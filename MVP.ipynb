{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "appended_data = []\n",
    "for year in range(1985, 2020):\n",
    "    result = pd.DataFrame()\n",
    "    url = 'https://www.basketball-reference.com/awards/awards_{}.html'.format(year)\n",
    "    url2 = 'https://www.basketball-reference.com/leagues/NBA_{}_per_game.html'.format(year)\n",
    "    url3 = 'https://www.basketball-reference.com/leagues/NBA_{}_advanced.html'.format(year)\n",
    "    \n",
    "    \n",
    "    #**********************EXTRACT DATA FROM FIRST URL**********************\n",
    "    temp = pd.read_html(url, header=[1])\n",
    "    temp[0].dropna(axis=1,inplace=True)\n",
    "    temp = temp[0][0:10]\n",
    "    temp = temp.drop('Rank', 1)\n",
    "    temp.insert(1, 'Year', year)\n",
    "    temp.insert(2, 'MVP', [1,0,0,0,0,0,0,0,0,0])\n",
    "    temp.columns = temp.columns.str.strip()\n",
    "    temp = temp.round(4)\n",
    "    #**********************EXTRACT DATA FROM SECOND URL**********************\n",
    "    temp2 = pd.read_html(url2)\n",
    "    temp2 = temp2[0].dropna(axis=1,how='all')\n",
    "    temp2['Player'] = temp2['Player'].str.replace('*','')\n",
    "    temp2.columns = temp2.columns.str.strip()\n",
    "    temp2 = temp2[temp2.Pos != 'Pos'] #get rid of random header rows\n",
    "    temp2 = temp2.round(4)\n",
    "    #Find intersecting columns\n",
    "    cols = list(np.intersect1d(temp.columns, temp2.columns))\n",
    "    #Remove cols temporarily that don't involve numbers because casting\n",
    "    #will add them back later when doing 'on = cols'\n",
    "    cols.remove('Player')\n",
    "    cols.remove('Tm')\n",
    "    #need to convert cols to float\n",
    "    temp[cols] = temp[cols].astype(float)\n",
    "    temp2[cols] = temp2[cols].astype(float) \n",
    "    \n",
    "    #add qualitative analysis back for on = within merge function\n",
    "    cols.append('Player')\n",
    "    cols.append('Tm')\n",
    "    \n",
    "    #MERGE TEMP AND TEMP2\n",
    "    result = temp.merge(temp2, how='inner', on=cols)\n",
    "    if (year == 1985):\n",
    "        result.to_csv('csv/TEMP1_2.csv')\n",
    "    #**********************EXTRACT DATA FROM THIRD URL**********************\n",
    "    temp3 = pd.read_html(url3)\n",
    "    temp3 = temp3[0].dropna(axis=1, how='all')\n",
    "    temp3 = temp3[temp3.Pos != 'Pos']\n",
    "    temp3['Player'] = temp3['Player'].str.replace('*','')\n",
    "    temp3 = temp3.drop('Rk', 1)\n",
    "    temp3.columns = temp3.columns.str.strip()\n",
    "    temp3 = temp3.rename(columns={\"MP\": \"TOT_MP\"})\n",
    "    temp3 = temp3.round(4)\n",
    "    #Find intersecting columns\n",
    "    cols = list(np.intersect1d(result.columns, temp3.columns))\n",
    "\n",
    "    #Remove cols temporarily that don't involve numbers because casting\n",
    "    #will add them back later when doing 'on = cols'\n",
    "    cols.remove('Player')\n",
    "    cols.remove('Tm')\n",
    "    cols.remove('Pos')\n",
    "    #need to convert cols to float\n",
    "    temp3[cols] = temp3[cols].astype(float) \n",
    "    temp3.to_csv('csv/temp3.csv')\n",
    "    #add qualitative analysis back for on = within merge function\n",
    "    cols.append('Player')\n",
    "    cols.append('Tm')\n",
    "    cols.append('Pos')\n",
    "    result = result.merge(temp3, how='inner', on=cols)\n",
    "    #add to list of data\n",
    "    appended_data.append(result)\n",
    "df = pd.concat(appended_data)\n",
    "df.to_csv('csv/historical_mvp_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Player     350\n",
       "Year       350\n",
       "MVP        350\n",
       "Age        350\n",
       "Tm         350\n",
       "First      350\n",
       "Pts Won    350\n",
       "Pts Max    350\n",
       "Share      350\n",
       "G          350\n",
       "MP         350\n",
       "PTS        350\n",
       "TRB        350\n",
       "AST        350\n",
       "STL        350\n",
       "BLK        350\n",
       "FG%        350\n",
       "FT%        350\n",
       "WS         350\n",
       "WS/48      350\n",
       "Rk         350\n",
       "Pos        350\n",
       "GS         350\n",
       "FG         350\n",
       "FGA        350\n",
       "3P         350\n",
       "3PA        350\n",
       "3P%        344\n",
       "2P         350\n",
       "2PA        350\n",
       "2P%        350\n",
       "eFG%       350\n",
       "FT         350\n",
       "FTA        350\n",
       "ORB        350\n",
       "DRB        350\n",
       "TOV        350\n",
       "PF         350\n",
       "TOT_MP     350\n",
       "PER        350\n",
       "TS%        350\n",
       "3PAr       350\n",
       "FTr        350\n",
       "ORB%       350\n",
       "DRB%       350\n",
       "TRB%       350\n",
       "AST%       350\n",
       "STL%       350\n",
       "BLK%       350\n",
       "TOV%       350\n",
       "USG%       350\n",
       "OWS        350\n",
       "DWS        350\n",
       "OBPM       350\n",
       "DBPM       350\n",
       "BPM        350\n",
       "VORP       350\n",
       "dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Player', 'Pos', 'Age', 'Tm', 'G', 'TOT_MP', 'PER', 'ORB%', 'DRB%',\n",
      "       'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS',\n",
      "       'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['PTS', 'BLK', 'TRB', 'AST', 'MP', 'STL'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-abc6939bf35b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m#     cols.remove('Pos')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m#need to convert cols to float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtemp3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mtemp3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csv/temp3.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PTS', 'BLK', 'TRB', 'AST', 'MP', 'STL'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "appended_data = []\n",
    "for year in range(1987, 1988):\n",
    "    result = pd.DataFrame()\n",
    "    url = 'https://www.basketball-reference.com/awards/awards_{}.html'.format(year)\n",
    "    url2 = 'https://www.basketball-reference.com/leagues/NBA_{}_per_game.html'.format(year)\n",
    "    url3 = 'https://www.basketball-reference.com/leagues/NBA_{}_advanced.html'.format(year)\n",
    "    \n",
    "    \n",
    "#     #**********************EXTRACT DATA FROM FIRST URL**********************\n",
    "#     temp = pd.read_html(url, header=[1])\n",
    "#     temp[0].dropna(axis=1,inplace=True)\n",
    "#     temp = temp[0][0:10]\n",
    "#     temp = temp.drop('Rank', axis=1)\n",
    "#     temp = temp.drop('FG%', axis=1)\n",
    "#     temp.insert(1, 'Year', year)\n",
    "#     temp.insert(2, 'MVP', [1,0,0,0,0,0,0,0,0,0])\n",
    "#     temp.columns = temp.columns.str.strip()\n",
    "    \n",
    "    #**********************EXTRACT DATA FROM SECOND URL**********************\n",
    "#     temp2 = pd.read_html(url2)\n",
    "#     temp2 = temp2[0].dropna(axis=1)\n",
    "#     temp2['Player'] = temp2['Player'].str.replace('*','')\n",
    "#     temp2.columns = temp2.columns.str.strip()\n",
    "#     temp2 = temp2[temp2.Pos != 'Pos']\n",
    "#    # temp2 = temp2.drop('FG%', axis=1)\n",
    "    \n",
    "#     #Find intersecting columns\n",
    "#     cols = list(np.intersect1d(temp.columns, temp2.columns))\n",
    "#     #Remove cols temporarily that don't involve numbers because casting\n",
    "#     #will add them back later when doing 'on = cols'\n",
    "#     cols.remove('Player')\n",
    "#     cols.remove('Tm')\n",
    "\n",
    "#     #need to convert cols to float\n",
    "#     temp[cols] = temp[cols].astype(float)\n",
    "#     temp2[cols] = temp2[cols].astype(float) \n",
    "    \n",
    "#     #add qualitative analysis back for on = within merge function\n",
    "\n",
    "#     #MERGE TEMP AND TEMP2\n",
    "#     result = temp.merge(temp2, how='inner', on=cols)\n",
    "#     print(temp2.columns)\n",
    "#     if (year == 1985):\n",
    "#         result.to_csv('csv/TEMP1_2.csv')\n",
    "    temp3 = pd.read_html(url3)\n",
    "    temp3 = temp3[0].dropna(axis=1, )\n",
    "    temp3 = temp3[temp3.Pos != 'Pos']\n",
    "    temp3['Player'] = temp3['Player'].str.replace('*','')\n",
    "    temp3 = temp3.drop('Rk', 1)\n",
    "    temp3.columns = temp3.columns.str.strip()\n",
    "    temp3 = temp3.rename(columns={\"MP\": \"TOT_MP\"})\n",
    "    temp3 = temp3.round(4)\n",
    "    print(temp3.columns)\n",
    "    #Find intersecting columns\n",
    "    #cols = list(np.intersect1d(result.columns, temp3.columns))\n",
    "    \n",
    "    #Remove cols temporarily that don't involve numbers because casting\n",
    "    #will add them back later when doing 'on = cols'\n",
    "#     cols.remove('Player')\n",
    "#     cols.remove('Tm')\n",
    "#     cols.remove('Pos')\n",
    "    #need to convert cols to float\n",
    "    temp3[cols] = temp3[cols].astype(float) \n",
    "    display(temp3)\n",
    "    temp3.to_csv('csv/temp3.csv')\n",
    "    #add qualitative analysis back for on = within merge function\n",
    "    cols.append('Player')\n",
    "    cols.append('Tm')\n",
    "    cols.append('Pos')\n",
    "    display(result)\n",
    "    result = result.merge(temp3, how='inner', on=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit648efa31c46c4c48a91bb723a20a4bc3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
